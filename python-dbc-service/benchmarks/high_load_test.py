#!/usr/bin/env python3
"""
HIGH LOAD —Ç–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–µ–¥–µ–ª–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ DBC —Å–µ—Ä–≤–∏—Å–∞
"""
import asyncio
import time
import statistics
import sys
import numpy as np
from pathlib import Path
from dataclasses import dataclass
from typing import List

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from utils.crc import CRC16ARC
from core.parser import FrameParser
from core.processor import DBCProcessor
from core.models import CommAddr, CommData, ParsedMessage
from interfaces.grpc.server import GRPCServer
from service import DBCService
from config import Settings, GRPCConfig, ProcessingConfig, MetricsConfig


@dataclass
class BenchmarkResult:
    test_name: str
    total_messages: int
    duration: float
    messages_per_second: float
    avg_latency_ms: float
    p95_latency_ms: float
    p99_latency_ms: float
    errors: int
    memory_usage_mb: float


class HighLoadTester:
    def __init__(self):
        self.results: List[BenchmarkResult] = []
    
    def create_test_frame(self, dev_addr: int = 1, msg_id: int = 100, payload: bytes = None) -> bytes:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ CAN –∫–∞–¥—Ä–∞"""
        if payload is None:
            payload = bytes([0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08])
        
        comm_addr = dev_addr | (msg_id << 5)
        crc_data = comm_addr.to_bytes(2, 'little') + payload
        crc = CRC16ARC.calculate(crc_data)
        
        return comm_addr.to_bytes(2, 'little') + payload + crc.to_bytes(2, 'little')
    
    def create_test_dbc_file(self, tmp_path: Path) -> Path:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ DBC —Ñ–∞–π–ª–∞"""
        dbc_content = '''VERSION ""

BO_ 100 TestMessage: 8 Vector__XXX
 SG_ Signal1 : 0|8@1+ (1,0) [0|255] "" Vector__XXX
 SG_ Signal2 : 8|16@1+ (0.1,0) [0|6553.5] "V" Vector__XXX

BO_ 200 BroadcastMessage: 8 Vector__XXX
 SG_ Status : 0|8@1+ (1,0) [0|255] "" Vector__XXX
 SG_ Counter : 8|16@1+ (1,0) [0|65535] "" Vector__XXX

BO_ 300 HighFreqMessage: 8 Vector__XXX
 SG_ Data : 0|64@1+ (1,0) [0|18446744073709551615] "" Vector__XXX
'''
        dbc_file = tmp_path / "benchmark.dbc"
        dbc_file.write_text(dbc_content)
        return dbc_file

    async def test_dbc_extreme_load(self, num_messages: int = 500000) -> BenchmarkResult:
        """–≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–´–ô —Ç–µ—Å—Ç DBC –æ–±—Ä–∞–±–æ—Ç–∫–∏ - –ø–æ–ª–º–∏–ª–ª–∏–æ–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–π!"""
        print(f"üöÄ EXTREME DBC LOAD TEST ({num_messages:,} messages)...")
        
        tmp_path = Path("/tmp/dbc_benchmark")
        tmp_path.mkdir(exist_ok=True)
        dbc_file = self.create_test_dbc_file(tmp_path)
        
        processor = DBCProcessor(dbc_file)
        await processor.initialize()
        
        # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = []
        for i in range(num_messages):
            comm_addr = CommAddr(
                dev_addr=(i % 31) + 1,
                msg_id=[100, 200, 300][i % 3],
                reserved=0
            )
            comm_data = CommData(
                frame_id=comm_addr,
                data=bytes([(i + j) % 256 for j in range(8)]),
                crc16=0x1234
            )
            messages.append(comm_data)
        
        print(f"   Created {len(messages):,} test messages...")
        
        errors = 0
        batch_size = 10000
        latency_samples = []
        
        start_time = time.perf_counter()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏ –Ω–∞ –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        for batch_start in range(0, num_messages, batch_size):
            batch_end = min(batch_start + batch_size, num_messages)
            batch = messages[batch_start:batch_end]
            
            batch_start_time = time.perf_counter()
            
            for i, message in enumerate(batch):
                try:
                    result = await processor.process_message(message, f"topic_{batch_start + i}")
                    if result is None:
                        errors += 1
                except Exception:
                    errors += 1
            
            batch_end_time = time.perf_counter()
            batch_latency = ((batch_end_time - batch_start_time) * 1000) / len(batch)
            latency_samples.append(batch_latency)
            
            if batch_start % (batch_size * 10) == 0:
                processed = batch_start + len(batch)
                rate = processed / (time.perf_counter() - start_time)
                print(f"   Processed {processed:,}/{num_messages:,} ({rate:,.0f} msg/s)")
        
        end_time = time.perf_counter()
        duration = end_time - start_time
        
        await processor.close()
        
        return BenchmarkResult(
            test_name="EXTREME DBC LOAD",
            total_messages=num_messages,
            duration=duration,
            messages_per_second=num_messages / duration,
            avg_latency_ms=statistics.mean(latency_samples) if latency_samples else 0,
            p95_latency_ms=float(np.percentile(latency_samples, 95)) if latency_samples else 0,
            p99_latency_ms=float(np.percentile(latency_samples, 99)) if latency_samples else 0,
            errors=errors,
            memory_usage_mb=self.get_memory_usage()
        )

    async def test_full_pipeline_extreme(self, num_frames: int = 200000) -> BenchmarkResult:
        """–≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–´–ô —Ç–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ pipeline - 200k –∫–∞–¥—Ä–æ–≤!"""
        print(f"üî• EXTREME FULL PIPELINE TEST ({num_frames:,} frames)...")
        
        tmp_path = Path("/tmp/dbc_benchmark")
        tmp_path.mkdir(exist_ok=True)
        dbc_file = self.create_test_dbc_file(tmp_path)
        
        settings = Settings(
            dbc_file=dbc_file,
            grpc=GRPCConfig(host="localhost", port=50061, max_workers=16),
            processing=ProcessingConfig(worker_pool_size=1),
            metrics=MetricsConfig(enabled=False)
        )
        
        service = DBCService(settings)
        await service.dbc_processor.initialize()
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞–¥—Ä—ã
        frames = [
            self.create_test_frame(dev_addr=(i % 31) + 1, msg_id=[100, 200, 300][i % 3])
            for i in range(num_frames)
        ]
        
        print(f"   Created {len(frames):,} test frames...")
        
        start_time = time.perf_counter()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è —Ç–æ—á–Ω–æ–π –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        batch_size = 5000
        for batch_start in range(0, num_frames, batch_size):
            batch_end = min(batch_start + batch_size, num_frames)
            batch_frames = frames[batch_start:batch_end]
            
            for i, frame in enumerate(batch_frames):
                await service.handle_message(f"topic_{batch_start + i}", frame)
            
            if batch_start % (batch_size * 10) == 0:
                processed = batch_start + len(batch_frames)
                rate = processed / (time.perf_counter() - start_time)
                print(f"   Processed {processed:,}/{num_frames:,} ({rate:,.0f} msg/s)")
        
        end_time = time.perf_counter()
        duration = end_time - start_time
        
        await service.shutdown()
        
        return BenchmarkResult(
            test_name="EXTREME FULL PIPELINE",
            total_messages=num_frames,
            duration=duration,
            messages_per_second=num_frames / duration,
            avg_latency_ms=(duration * 1000) / num_frames,
            p95_latency_ms=0,  # –°–ª–æ–∂–Ω–æ –∏–∑–º–µ—Ä–∏—Ç—å —Ç–æ—á–Ω–æ –¥–ª—è —Ç–∞–∫–æ–≥–æ –æ–±—ä–µ–º–∞
            p99_latency_ms=0,
            errors=service.stats["errors"],
            memory_usage_mb=self.get_memory_usage()
        )

    async def test_concurrent_massive(self, num_frames: int = 100000, concurrency: int = 32) -> BenchmarkResult:
        """–ú–ê–°–°–ò–í–ù–´–ô –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π —Ç–µ—Å—Ç - 100k –∫–∞–¥—Ä–æ–≤ –Ω–∞ 32 –≤–æ—Ä–∫–µ—Ä–∞—Ö!"""
        print(f"‚ö° MASSIVE CONCURRENT TEST ({num_frames:,} frames, {concurrency} workers)...")
        
        tmp_path = Path("/tmp/dbc_benchmark")
        tmp_path.mkdir(exist_ok=True)
        dbc_file = self.create_test_dbc_file(tmp_path)
        
        settings = Settings(
            dbc_file=dbc_file,
            grpc=GRPCConfig(host="localhost", port=50062, max_workers=concurrency),
            processing=ProcessingConfig(worker_pool_size=1),
            metrics=MetricsConfig(enabled=False)
        )
        
        service = DBCService(settings)
        await service.dbc_processor.initialize()
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞–¥—Ä—ã
        frames = [
            self.create_test_frame(dev_addr=(i % 31) + 1, msg_id=[100, 200, 300][i % 3])
            for i in range(num_frames)
        ]
        
        print(f"   Created {len(frames):,} test frames...")
        print(f"   Starting concurrent processing with {concurrency} workers...")
        
        start_time = time.perf_counter()
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ chunks –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        chunk_size = max(1, num_frames // concurrency)
        chunks = [frames[i:i + chunk_size] for i in range(0, len(frames), chunk_size)]
        
        async def process_chunk(chunk, chunk_id):
            for i, frame in enumerate(chunk):
                await service.handle_message(f"topic_{chunk_id}_{i}", frame)
        
        # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö chunks
        tasks = [process_chunk(chunk, i) for i, chunk in enumerate(chunks)]
        await asyncio.gather(*tasks)
        
        end_time = time.perf_counter()
        duration = end_time - start_time
        
        await service.shutdown()
        
        return BenchmarkResult(
            test_name=f"MASSIVE CONCURRENT (x{concurrency})",
            total_messages=num_frames,
            duration=duration,
            messages_per_second=num_frames / duration,
            avg_latency_ms=duration * 1000 / num_frames,
            p95_latency_ms=0,
            p99_latency_ms=0,
            errors=service.stats["errors"],
            memory_usage_mb=self.get_memory_usage()
        )

    def get_memory_usage(self) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤ MB"""
        try:
            import psutil
            process = psutil.Process()
            return process.memory_info().rss / 1024 / 1024
        except ImportError:
            return 0.0

    def print_results(self):
        """–ü–µ—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ HIGH LOAD —Ç–µ—Å—Ç–æ–≤"""
        print("\n" + "="*80)
        print("üèÜ HIGH LOAD BENCHMARK RESULTS")
        print("="*80)
        
        for result in self.results:
            print(f"\nüöÄ {result.test_name}")
            print(f"   Messages:     {result.total_messages:,}")
            print(f"   Duration:     {result.duration:.2f}s")
            print(f"   Throughput:   {result.messages_per_second:,.0f} msg/s")
            print(f"   Avg Latency:  {result.avg_latency_ms:.3f}ms")
            if result.p95_latency_ms > 0:
                print(f"   P95 Latency:  {result.p95_latency_ms:.3f}ms")
                print(f"   P99 Latency:  {result.p99_latency_ms:.3f}ms")
            print(f"   Errors:       {result.errors}")
            if result.memory_usage_mb > 0:
                print(f"   Memory:       {result.memory_usage_mb:.1f}MB")
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        if self.results:
            best = max(self.results, key=lambda x: x.messages_per_second)
            print(f"\nüèÜ ABSOLUTE BEST: {best.test_name}")
            print(f"    üöÄ PEAK PERFORMANCE: {best.messages_per_second:,.0f} msg/s")
            
            if best.messages_per_second >= 300000:
                print("üéâ INCREDIBLE! 300k+ msg/s achieved!")
            elif best.messages_per_second >= 200000:
                print("üî• EXCELLENT! 200k+ msg/s achieved!")
            elif best.messages_per_second >= 100000:
                print("‚úÖ GREAT! 100k+ msg/s target exceeded!")


async def main():
    """–ó–∞–ø—É—Å–∫ HIGH LOAD —Ç–µ—Å—Ç–æ–≤"""
    tester = HighLoadTester()
    
    print("üöÄ STARTING HIGH LOAD TESTS...")
    print("üéØ Testing the LIMITS of optimized DBC service")
    print("‚ö†Ô∏è  This will take 10-15 minutes and use significant resources")
    print("")
    
    try:
        # –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã
        tests = [
            tester.test_dbc_extreme_load(500000),       # 500k —Å–æ–æ–±—â–µ–Ω–∏–π DBC
            tester.test_full_pipeline_extreme(200000),   # 200k full pipeline  
            tester.test_concurrent_massive(100000, 32), # 100k concurrent x32
        ]
        
        for test in tests:
            print(f"\n{'='*60}")
            result = await test
            tester.results.append(result)
            print(f"‚úÖ COMPLETED: {result.messages_per_second:,.0f} msg/s")
        
        tester.print_results()
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  HIGH LOAD tests interrupted")
    except Exception as e:
        print(f"\n‚ùå HIGH LOAD test failed: {e}")
        raise


if __name__ == "__main__":
    try:
        import uvloop
        uvloop.install()
        print("üîß Using uvloop for maximum performance")
    except ImportError:
        print("‚ö†Ô∏è  uvloop not available")
    
    asyncio.run(main())